{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import style\n",
    "style.use('ggplot')    \n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    " \n",
    "def write_excel_xlsx(path, sheet_name, value):\n",
    "    index = len(value)\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "    for i in range(0, index):\n",
    "        for j in range(0, len(value[i])):\n",
    "            sheet.cell(row=i+1, column=j+1, value=str(value[i][j]))\n",
    "    workbook.save(path)\n",
    "    print(\"xlsx格式表格写入数据成功！\")\n",
    " \n",
    " \n",
    "def read_excel_xlsx(path, sheet_name):\n",
    "    workbook = openpyxl.load_workbook(path)\n",
    "    # sheet = wb.get_sheet_by_name(sheet_name)这种方式已经弃用，不建议使用\n",
    "    sheet = workbook[sheet_name]\n",
    "    for row in sheet.rows:\n",
    "        for cell in row:\n",
    "            print(cell.value, \"\\t\", end=\"\")\n",
    "        print('xlsx格式表格读入数据成功！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(dt):\n",
    "    df_resolve_new = pd.read_csv(f'stat{dt}/resolve_stat/gdl_jrs_msg_parse_baseline_all.csv',\n",
    "                             index_col = False)\n",
    "    df_resolve_init = pd.read_csv('resolve/gdl_jrs_msg_parse_baseline_all.csv',index_col = False)\n",
    "    df_resolve_new.drop_duplicates(inplace = True)\n",
    "    df_resolve_init.drop_duplicates(inplace = True)\n",
    "    df_resolve = df_resolve_init.append(df_resolve_new).sort_values('dt').reset_index(drop = True)\n",
    "    df_resolve.drop_duplicates(inplace = True)\n",
    "    df_resolve.to_csv('resolve/gdl_jrs_msg_parse_baseline_all.csv',index = False)\n",
    "    return df_resolve\n",
    "def month_day_test(dt):\n",
    "    years = int(dt.split('-')[-2])\n",
    "    if int(dt.split('-')[-1]) in [1,3,5,7,8,10,12]:\n",
    "        day_list = list(range(1,32))\n",
    "    elif int(dt.split('-')[-1]) in [4,6,9,11]:\n",
    "        day_list = list(range(1,31))\n",
    "    elif (years%4==0 and years%100!=0) or years%400==0:\n",
    "        day_list = list(range(1,30))\n",
    "    else:\n",
    "        day_list = list(range(1,29))\n",
    "    return day_list\n",
    "def huanbi(data):\n",
    "    result = []\n",
    "    data = list(data)\n",
    "    for i in range(len(data)):\n",
    "        if i == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append((data[i]-(data[i-1]))/data[i-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_index(df_resolve):\n",
    "    # 手机号缺失大于1的日期\n",
    "    phone_miss_over1 = df_resolve[df_resolve['phone_miss']>1][['dt','phone_miss']].reset_index(drop = True)\n",
    "    df_nuique_cloumns = df_resolve.any()\n",
    "    df_nuique_cloumns = df_nuique_cloumns.reset_index()\n",
    "    df_miss_cloumns = df_nuique_cloumns[df_nuique_cloumns[0]==1]['index'].reset_index(drop = True)\n",
    "    df_not_miss_columns = df_nuique_cloumns[df_nuique_cloumns[0]==0]['index'].reset_index(drop = True)\n",
    "    df_miss_cloumns.drop([0],inplace = True)\n",
    "    df_resolve_all = df_resolve[df_miss_cloumns]\n",
    "    df_miss_cloumns = list(df_miss_cloumns.drop([7,8]))\n",
    "    # 底层数据缺失的日期\n",
    "    df_missing_data_dt = df_resolve_all[(df_resolve_all['unique_num']==0)|(df_resolve_all['total_num']==0)][['dt','unique_num','total_num']].reset_index(drop = True)\n",
    "    # 未统计日期\n",
    "    month_day = {\"month\":[],\"kill_day\":[]}\n",
    "    df_resolve_all['month'] = df_resolve_all['dt'].apply(lambda x:x[:-3])\n",
    "    df_month_test = df_resolve_all.groupby(['month'])['dt'].apply(lambda x:len(x))\n",
    "    for i in df_month_test.index:\n",
    "        month_day['month'].append(i)\n",
    "        day_list = month_day_test(i)\n",
    "        day_list_resolve = list(df_resolve_all[df_resolve_all['month'] == i]['dt'].apply(lambda x:int(x[-2:])))\n",
    "        day_kill = list(set(day_list).difference(set(day_list_resolve)))\n",
    "        month_day['kill_day'].append(day_kill)\n",
    "    month_kill_day = pd.DataFrame(month_day)\n",
    "    df_resolve_all = df_resolve_all[~((df_resolve_all['unique_num']==0)|(df_resolve_all['total_num']==0))].reset_index(drop = True)\n",
    "    # 缺失率及增长率\n",
    "    for key in df_miss_cloumns:\n",
    "        if key =='total_num' or key =='unique_num':\n",
    "            df_resolve_all[f'{key}_增长率'] = huanbi(df_resolve_all[key])\n",
    "        else:\n",
    "            key1 = key[:-5]\n",
    "            df_resolve_all[f'{key1}_缺失率'] = df_resolve_all[key]/df_resolve_all['total_num']\n",
    "            df_resolve_all[f'{key1}_缺失量_增长率'] = huanbi(df_resolve_all[key])\n",
    "            df_resolve_all[f'{key1}_缺失率_增长率'] = huanbi(df_resolve_all[f'{key1}_缺失率'])\n",
    "    col1 = list(df_resolve_all.columns)\n",
    "    col1 = sorted(col1)\n",
    "    for i in ['table_name','dt','month']:\n",
    "        k = col1.index(i)\n",
    "        col1.append(col1[k])\n",
    "        col1.remove(col1[k])\n",
    "    df_resolve_all = df_resolve_all[col1]\n",
    "    #保存结果\n",
    "    with pd.ExcelWriter('result_excel/baseline_all.xlsx') as writer:\n",
    "        phone_miss_over1.to_excel(writer, sheet_name='手机号缺失大于1的解析日期',index = False)\n",
    "        df_missing_data_dt.to_excel(writer, sheet_name='数据缺失日期',index = False)\n",
    "        df_resolve_all.to_excel(writer, sheet_name='统计指标结果汇总',index = False)\n",
    "        month_kill_day.to_excel(writer, sheet_name='未统计日期',index = False)\n",
    "    return df_resolve_all,df_miss_cloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mechanism_miss',\n",
       " 'business_date_miss',\n",
       " 'address_1_miss',\n",
       " 'address_2_miss',\n",
       " 'total_num',\n",
       " 'unique_num']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss_cloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss_cloumns_desc = {\"address_1\":\"地址1\",\"address_2\":\"地址2\",\"mechanism\":\"机构名称\",\"business_date\":\"业务时间\",\"unique_num\":\"独立用户数\",\"total_num\":\"短信条数\"}\n",
    "def report_week_data(date_start,date_end,df_resolve_all,df_miss_cloumns,df_miss_cloumns_desc):\n",
    "    show_data = df_resolve_all[(df_resolve_all['dt']>=date_start) & (df_resolve_all['dt']<=date_end)]\n",
    "    if not os.path.exists(f'result_picture/result_{date_start}_{date_end}'):\n",
    "        os.mkdir(f'result_picture/result_{date_start}_{date_end}')\n",
    "    with pd.ExcelWriter(f'result_excel/baseline_all_var.xlsx') as writer:\n",
    "        for j in df_miss_cloumns:\n",
    "            index_list0 = [i for i in show_data.columns if j[:-5] in i]+['dt','month']\n",
    "            index_data = show_data[index_list0]\n",
    "            if 'miss' in j:\n",
    "                key = j[:-5]\n",
    "                desc = df_miss_cloumns_desc[key]\n",
    "                for values in ['miss','缺失率','缺失率_增长率','缺失量_增长率']:\n",
    "                    plt.figure(figsize=(10, 8), dpi=80)\n",
    "                    if values =='miss':\n",
    "                        plt.bar(index_data['dt'],index_data[f'{key}_{values}'],color = \"#87CEFA\")\n",
    "                        plt.ylabel(f'解析{desc}缺失值总量(亿)')\n",
    "                        for a,b in zip(index_data['dt'],index_data[f'{key}_miss']):\n",
    "                            plt.text(a, b-0.3,'%.2f'%round(b/100000000,3), ha = 'center',va = 'bottom',fontsize=15)\n",
    "                        plt.savefig(f'result_picture/result_{date_start}_{date_end}/{date_start}_{date_end}_{desc}缺失总量', dpi=300)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        plt.plot(index_data['dt'],index_data[f'{key}_{values}'],color = \"#87CEFA\")\n",
    "                        if '增长率' in values:\n",
    "                            desc1 = values.split('_')[0]\n",
    "                            plt.ylabel(f'解析{desc}{desc1}的变化趋势')\n",
    "                        else:\n",
    "                            plt.ylabel(f'解析{desc}缺失率')\n",
    "                        for a,b in zip(index_data['dt'],index_data[f'{key}_{values}']):\n",
    "                            plt.text(a, b,'%.2f'%b, ha = 'center',va = 'bottom',fontsize=15)\n",
    "                        plt.savefig(f'result_picture/result_{date_start}_{date_end}/{date_start}_{date_end}_{desc}{values}', dpi=300)\n",
    "                        plt.close()\n",
    "            else:\n",
    "                key = j\n",
    "                desc = df_miss_cloumns_desc[key]\n",
    "                for values in [f'{key}','增长率']:\n",
    "                    plt.figure(figsize=(10, 5), dpi=80)\n",
    "                    if values !='增长率':\n",
    "                        plt.bar(index_data['dt'],index_data[f'{key}'],color = \"#87CEFA\")\n",
    "                        plt.ylabel(f'解析{desc}总量(亿)')\n",
    "                        for a,b in zip(index_data['dt'],index_data[f'{key}']):\n",
    "                            plt.text(a, b-0.3,'%.2f'%round(b/100000000,3), ha = 'center',va = 'bottom',fontsize=15)\n",
    "                        plt.savefig(f'result_picture/result_{date_start}_{date_end}/{date_start}_{date_end}_{desc}缺失总量', dpi=300)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        plt.plot(index_data['dt'],index_data[f'{key}_{values}'],color = \"#87CEFA\")\n",
    "                        desc1 = values\n",
    "                        plt.ylabel(f'解析{desc}{desc1}的变化趋势')\n",
    "                        for a,b in zip(index_data['dt'],index_data[f'{key}_{values}']):\n",
    "                            plt.text(a, b,'%.2f'%b, ha = 'center',va = 'bottom',fontsize=15)\n",
    "                        plt.savefig(f'result_picture/result_{date_start}_{date_end}/{date_start}_{date_end}_{desc}{values}', dpi=300)\n",
    "                        plt.close()\n",
    "            if os.path.exists('result_excel/baseline_all_var.xlsx'):\n",
    "                index_data1 = pd.read_excel('result_excel/baseline_all_var.xlsx',sheet_name = f'{desc}',index = False)\n",
    "                index_data1 = index_data1.append(index_data)\n",
    "            else :\n",
    "                index_data1 = index_data\n",
    "            index_data1.to_excel(writer, sheet_name=f'{desc}',index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_resolve = merge_df('20200920')\n",
    "df_resolve_all,df_miss_cloumns = all_index(df_resolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = '2019-03-01'\n",
    "date_final = '2019-06-08'\n",
    "def main(date_start,date_final):\n",
    "    while date_start<date_final:\n",
    "        print(date_start)\n",
    "        date_start1 = datetime.strptime(date_start, \"%Y-%m-%d\")\n",
    "        date_end = str(date_start1 - timedelta(days=-6))[:-9]\n",
    "        report_week_data(date_start,date_end,df_resolve_all,df_miss_cloumns,df_miss_cloumns_desc)\n",
    "        date_start = date_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-01\n",
      "2019-03-07\n",
      "2019-03-13\n",
      "2019-03-19\n",
      "2019-03-25\n",
      "2019-03-31\n",
      "2019-04-06\n",
      "2019-04-12\n",
      "2019-04-18\n",
      "2019-04-24\n",
      "2019-04-30\n",
      "2019-05-06\n",
      "2019-05-12\n",
      "2019-05-18\n",
      "2019-05-24\n",
      "2019-05-30\n"
     ]
    }
   ],
   "source": [
    "main(date_start,date_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
